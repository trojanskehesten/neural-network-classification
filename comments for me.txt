Комментарии для диссертации
# Большие значения (0,01 – 1) будут соответствовать большому значению шага коррекции. При этом алгоритм будет работать быстрее 
# (т.е. для поиска минимума функции ошибки потребуется меньше шагов), однако  снижается точность настройки на минимум, что 
# потенциально увеличит ошибку обучения. (Покажу график с 1600 и 0,02-0,0001 как он прыгает)
#
# Малые значения коэффициента (0,0001 – 0,001) соответствуют меньшему шагу коррекции весов. При этом число шагов (или эпох), 
# требуемое для поиска оптимума, как правило, увеличивается, но возрастает и точность настройки на минимум, что потенциально 
# уменьшает ошибку обучения. На практике коэффициент скорости обучения обычно подбирают экспериментально.
# При малых значениях я и так имею 100% точность и мне не требуется длительное время обучать по сути дела бесполезно 
# сеть (перфекционизм)
#
# speed экспериментально по графику, чтобы уменьшалась скорость "равноразрядно", т.е. равномерно в пределах одного 
# десятичного разряда и минимальное значение приближалось к заданному 0,001
